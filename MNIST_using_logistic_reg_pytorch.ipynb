{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Logistic Regression in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.mnist.MNIST"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=L size=28x28 at 0x20101F29308>, tensor(5))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[44]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print(\"Label:\",label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "image, label = dataset[168]\n",
    "plt.imshow(image, cmap='gray')\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting images to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch datasets allow us to specify one or more transformation functions which are applied to the images as they are loaded. torchvision.transforms contains many such predefined functions, and we'll use the ToTensor transform to convert images into PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(root='data/',\n",
    "               train=True,\n",
    "               transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_tensor, label = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is now converted to a 1x28x28 tensor. The first dimension is used to keep track of the color channels. Since images in the MNIST dataset are grayscale, there's just one channel. Other datasets have images with color, in which case there are 3 channels: red, green and blue (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0039, 0.6039, 0.9922, 0.3529, 0.0000],\n",
      "         [0.0000, 0.5451, 0.9922, 0.7451, 0.0078],\n",
      "         [0.0000, 0.0431, 0.7451, 0.9922, 0.2745],\n",
      "         [0.0000, 0.0000, 0.1373, 0.9451, 0.8824],\n",
      "         [0.0000, 0.0000, 0.0000, 0.3176, 0.9412]]])\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor[:,10:15,10:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image_tensor[0,10:15,10:15], cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10000)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds, val_ds = random_split(dataset,[50000,10000])\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now created data loaders to help us load the data in batches. We'll use a batch size of 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set shuffle=True for the training dataloader, so that the batches generated in each epoch are different, and this randomization helps generalize & speed up the training process. On the other hand, since the validation dataloader is used only for evaluating the model, there is no need to shuffle the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* we will use nn.Linear to create the model instead of defining and initializing the matrices manually.\n",
    "\n",
    "* Since nn.Linear expects the each training example to be a vector, each 1x28x28 image tensor needs to be flattened out into a  vector of size 784 (28*28), before being passed into the model.\n",
    "\n",
    "* The output for each image is vector of size 10, with each element of the vector signifying the probability a particular target label (i.e. 0 to 9). The predicted label for an image is simply the one with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "input_size = 28*28\n",
    "num_classes = 10\n",
    "\n",
    "model = nn.Linear(input_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784])\n",
      "Parameter containing:\n",
      "tensor([[-0.0133, -0.0333, -0.0320,  ...,  0.0133,  0.0216, -0.0258],\n",
      "        [ 0.0182,  0.0097,  0.0076,  ..., -0.0038, -0.0202, -0.0058],\n",
      "        [ 0.0116,  0.0321, -0.0207,  ..., -0.0095, -0.0258,  0.0008],\n",
      "        ...,\n",
      "        [-0.0179, -0.0330, -0.0077,  ...,  0.0113, -0.0304,  0.0227],\n",
      "        [ 0.0341, -0.0169, -0.0009,  ..., -0.0288, -0.0050, -0.0043],\n",
      "        [ 0.0069,  0.0265,  0.0219,  ..., -0.0026, -0.0196, -0.0157]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.weight.shape)\n",
    "print(model.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "Parameter containing:\n",
      "tensor([-0.0148,  0.0043,  0.0177,  0.0207,  0.0318,  0.0056,  0.0269,  0.0100,\n",
      "         0.0269,  0.0089], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model.bias.shape)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are a total of 7850 parameters here, conceptually nothing has changed so far. Let's try and generate some outputs using our model. We'll take the first batch of 100 images from our dataset, and pass them into our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 7, 0, 7, 1, 9, 4, 7, 6, 3, 9, 7, 4, 8, 3, 7, 0, 4, 7, 3, 2, 6, 8,\n",
      "        9, 1, 4, 4, 2, 7, 7, 9, 8, 5, 1, 2, 7, 6, 5, 0, 9, 2, 9, 0, 0, 2, 4, 3,\n",
      "        8, 8, 0, 7, 1, 5, 9, 9, 8, 3, 7, 2, 3, 4, 0, 5, 7, 6, 8, 9, 6, 0, 3, 6,\n",
      "        5, 3, 7, 8, 1, 2, 7, 8, 0, 1, 6, 0, 4, 6, 2, 1, 9, 0, 9, 8, 9, 2, 9, 8,\n",
      "        4, 7, 3, 0, 4, 3, 8, 7, 1, 9, 2, 7, 0, 6, 1, 5, 9, 5, 6, 9, 1, 0, 0, 6,\n",
      "        9, 0, 3, 8, 6, 3, 7, 8])\n",
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128, 784])\n",
      "tensor([[ 0.1275, -0.2032,  0.1874,  ...,  0.1625,  0.3043, -0.0748],\n",
      "        [-0.0255, -0.2329,  0.1969,  ..., -0.2328,  0.2672,  0.1102],\n",
      "        [ 0.1434, -0.2469,  0.1680,  ...,  0.0257,  0.1264,  0.2521],\n",
      "        ...,\n",
      "        [-0.2650, -0.2135,  0.3101,  ..., -0.1722,  0.1493, -0.1087],\n",
      "        [-0.0082,  0.0394,  0.1900,  ..., -0.0931,  0.1610,  0.2716],\n",
      "        [-0.0089, -0.1228,  0.0008,  ..., -0.2496,  0.0054,  0.0106]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    print(labels)\n",
    "    \n",
    "    print(images.shape)\n",
    "    images = images.view(-1,28*28)  # Images should be flattened or order (28x28) before feeding to model..from ([128, 1, 28, 28]) to ([128, 784])\n",
    "    print(images.shape)\n",
    "    \n",
    "    outputs=model(images)\n",
    "    print(outputs)\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 784]) torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0106,  0.0174, -0.0110,  ..., -0.0333,  0.0302, -0.0020],\n",
       "         [-0.0234,  0.0118, -0.0008,  ..., -0.0141,  0.0117, -0.0063],\n",
       "         [ 0.0071, -0.0309, -0.0152,  ..., -0.0279, -0.0303,  0.0001],\n",
       "         ...,\n",
       "         [-0.0289, -0.0108,  0.0016,  ...,  0.0080, -0.0136, -0.0153],\n",
       "         [ 0.0011,  0.0073, -0.0253,  ..., -0.0116, -0.0047, -0.0303],\n",
       "         [ 0.0352, -0.0107,  0.0285,  ..., -0.0158, -0.0037, -0.0101]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0045, -0.0142, -0.0072, -0.0225, -0.0188, -0.0255, -0.0076,  0.0235,\n",
       "          0.0337, -0.0198], requires_grad=True)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.linear.weight.shape, model.linear.bias.shape)\n",
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outputs.shape :  torch.Size([128, 10])\n",
      "Sample outputs :\n",
      " tensor([[ 0.1555,  0.0236, -0.1233, -0.3108,  0.2147, -0.1315,  0.1643, -0.4852,\n",
      "         -0.1869, -0.1027],\n",
      "        [ 0.1669,  0.1121, -0.2051, -0.2069,  0.0094, -0.0496, -0.1440,  0.1072,\n",
      "         -0.2894, -0.1055]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_loader:\n",
    "    outputs = model(images)\n",
    "    break\n",
    "print('outputs.shape : ', outputs.shape)\n",
    "print('Sample outputs :\\n', outputs[:2].data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of the 100 input images, we get 10 outputs, one for each class. The elements of each output row must lie between 0 to 1 and add up to 1,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function is included in the torch.nn.functional package, and requires us to specify a dimension along which the softmax must be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample probabilities:\n",
      " tensor([[0.1236, 0.1083, 0.0935, 0.0775, 0.1311, 0.0928, 0.1247, 0.0651, 0.0878,\n",
      "         0.0955],\n",
      "        [0.1242, 0.1175, 0.0856, 0.0854, 0.1061, 0.1000, 0.0910, 0.1170, 0.0787,\n",
      "         0.0946]])\n",
      "Sum:  1.0\n"
     ]
    }
   ],
   "source": [
    "probs = F.softmax(outputs, dim=1)\n",
    "\n",
    "# Look at sample probabilities\n",
    "print(\"Sample probabilities:\\n\", probs[:2].data)\n",
    "\n",
    "# Add up the probabilities of an output row\n",
    "print(\"Sum: \", torch.sum(probs[0]).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can determine the predicted label for each image by simply choosing the index of the element with the highest probability in each output row. This is done using torch.max, which returns the largest element and the index of the largest element along a particular dimension of a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 0, 0, 1, 6, 0, 7, 1, 0, 7, 6, 6, 4, 1, 0, 0, 0, 0, 7, 6, 0, 6, 6, 0,\n",
      "        0, 0, 6, 6, 1, 6, 6, 0, 0, 0, 1, 0, 6, 6, 1, 1, 6, 6, 0, 0, 6, 0, 1, 6,\n",
      "        0, 6, 2, 6, 1, 0, 0, 7, 1, 0, 0, 1, 0, 1, 8, 0, 0, 0, 1, 0, 6, 0, 6, 6,\n",
      "        1, 1, 0, 6, 1, 0, 6, 6, 0, 6, 0, 1, 0, 5, 0, 7, 6, 6, 0, 6, 6, 1, 0, 6,\n",
      "        0, 1, 0, 4, 1, 0, 1, 0, 6, 4, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 6, 1, 1, 6,\n",
      "        6, 6, 0, 6, 6, 6, 0, 1])\n",
      "tensor([0.1311, 0.1242, 0.1270, 0.1365, 0.1377, 0.1379, 0.1360, 0.1354, 0.1222,\n",
      "        0.1392, 0.1896, 0.1488, 0.1266, 0.1277, 0.1387, 0.1251, 0.1340, 0.1605,\n",
      "        0.1306, 0.1251, 0.1186, 0.1472, 0.1229, 0.1161, 0.1226, 0.1147, 0.1150,\n",
      "        0.1317, 0.1210, 0.1493, 0.1674, 0.1402, 0.1261, 0.1210, 0.1469, 0.1538,\n",
      "        0.1269, 0.1937, 0.1270, 0.1307, 0.1137, 0.1329, 0.1194, 0.1217, 0.1509,\n",
      "        0.1389, 0.1625, 0.1448, 0.1502, 0.1576, 0.1156, 0.1276, 0.1588, 0.1287,\n",
      "        0.1256, 0.1342, 0.1212, 0.1382, 0.1197, 0.1292, 0.1303, 0.1572, 0.1189,\n",
      "        0.1216, 0.1390, 0.1549, 0.1327, 0.1159, 0.1457, 0.1377, 0.1555, 0.1198,\n",
      "        0.1299, 0.1322, 0.1319, 0.1564, 0.1419, 0.1517, 0.1389, 0.1318, 0.1287,\n",
      "        0.1436, 0.1243, 0.1451, 0.1212, 0.1306, 0.1504, 0.1486, 0.1417, 0.1639,\n",
      "        0.1442, 0.1465, 0.1427, 0.1296, 0.1252, 0.1716, 0.1423, 0.1553, 0.1268,\n",
      "        0.1215, 0.1289, 0.1358, 0.1433, 0.1368, 0.1361, 0.1340, 0.1406, 0.1321,\n",
      "        0.1204, 0.1371, 0.1171, 0.1285, 0.1447, 0.1243, 0.1354, 0.1265, 0.1156,\n",
      "        0.1283, 0.1172, 0.1312, 0.1481, 0.1363, 0.1298, 0.1284, 0.1414, 0.1429,\n",
      "        0.1266, 0.1203], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "max_probs, preds = torch.max(probs, dim=1)\n",
    "print(preds)\n",
    "print(max_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 0, 5, 6, 6, 8, 3, 4, 5, 3, 4, 4, 9, 4, 1, 0, 5, 2, 5, 3, 1, 2, 8, 9,\n",
       "        8, 1, 3, 3, 4, 5, 4, 5, 7, 3, 9, 8, 3, 4, 7, 6, 3, 7, 9, 3, 6, 6, 4, 2,\n",
       "        2, 9, 5, 6, 2, 0, 0, 2, 3, 4, 5, 6, 2, 4, 1, 6, 5, 6, 9, 1, 5, 0, 4, 5,\n",
       "        4, 4, 7, 4, 7, 2, 3, 8, 3, 3, 9, 9, 5, 3, 0, 0, 3, 9, 3, 8, 2, 7, 4, 4,\n",
       "        2, 2, 7, 5, 7, 3, 2, 1, 4, 7, 7, 5, 5, 7, 1, 8, 4, 7, 7, 5, 8, 4, 7, 2,\n",
       "        6, 8, 2, 1, 6, 4, 7, 6])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0938)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(outputs, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* While the accuracy is a great way for us (humans) to evaluate the model, it can't be used as a loss function for optimizing our model using gradient descent, for the following reasons:\n",
    "\n",
    "* It's not a differentiable function. torch.max and == are both non-continuous and non-differentiable operations, so we can't use the accuracy for computing gradients w.r.t the weights and biases.\n",
    "\n",
    "* It doesn't take into account the actual probabilities predicted by the model, so it can't provide sufficient feedback for incremental improvements.\n",
    "\n",
    "* Due to these reasons, accuracy is a great evaluation metric for classification, but not a good loss function. A commonly used loss function for classification problems is the cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3456, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(outputs, labels)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the cross entropy is the negative logarithm of the predicted probability of the correct label averaged over all training samples, one way to interpret the resulting number e.g. 2.23 is look at e^-2.23 which is around 0.1 as the predicted probability of the correct label, on average. Lower the loss, better the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    for batch in train_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Compute gradients\n",
    "        # Update weights\n",
    "        # Reset gradients\n",
    "    \n",
    "    # Validation phase\n",
    "    for batch in val_loader:\n",
    "        # Generate predictions\n",
    "        # Calculate loss\n",
    "        # Calculate metrics (accuracy etc.)\n",
    "    # Calculate average validation loss & metrics\n",
    "    \n",
    "    # Log epoch, loss & metrics for inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        return out\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        out = self(images)                    # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
    "        acc = accuracy(out, labels)           # Calculate accuracy\n",
    "        return {'val_loss': loss, 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "    \n",
    "model = MnistModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        # Training Phase \n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        # Validation phase\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit function records the validation loss and metric from each epoch and returns a history of the training process. This is useful for debuggin & visualizing the training process. Before we train the model, let's see how the model performs on the validation set with the initial set of randomly initialized weights & biases.\n",
    "\n",
    "Configurations like batch size, learning rate etc. need to picked in advance while training machine learning models, and are called hyperparameters. Picking the right hyperparameters is critical for training an accurate model within a reasonable amount of time, and is an active area of research and experimentation. Feel free to try different learning rates and see how it affects the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 2.324141025543213, 'val_acc': 0.09028876572847366}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result0 = evaluate(model, val_loader)\n",
    "result0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial accuracy is around 9%, which is what one might expect from a randomly intialized model (since it has a 1 in 10 chance of getting a label right by guessing randomly). Also note that we are using the .format method with the message string to print only the first four digits after the decimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.9556, val_acc: 0.6223\n",
      "Epoch [1], val_loss: 1.6869, val_acc: 0.7232\n",
      "Epoch [2], val_loss: 1.4860, val_acc: 0.7553\n",
      "Epoch [3], val_loss: 1.3344, val_acc: 0.7732\n",
      "Epoch [4], val_loss: 1.2180, val_acc: 0.7859\n"
     ]
    }
   ],
   "source": [
    "history1 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 1.1266, val_acc: 0.7977\n",
      "Epoch [1], val_loss: 1.0535, val_acc: 0.8040\n",
      "Epoch [2], val_loss: 0.9935, val_acc: 0.8113\n",
      "Epoch [3], val_loss: 0.9436, val_acc: 0.8173\n",
      "Epoch [4], val_loss: 0.9014, val_acc: 0.8218\n"
     ]
    }
   ],
   "source": [
    "history2 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.6805, val_acc: 0.8495\n",
      "Epoch [1], val_loss: 0.5899, val_acc: 0.8606\n",
      "Epoch [2], val_loss: 0.5385, val_acc: 0.8690\n",
      "Epoch [3], val_loss: 0.5051, val_acc: 0.8737\n",
      "Epoch [4], val_loss: 0.4809, val_acc: 0.8768\n"
     ]
    }
   ],
   "source": [
    "history3 = fit(5, 0.01, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.4788, val_acc: 0.8772\n",
      "Epoch [1], val_loss: 0.4767, val_acc: 0.8779\n",
      "Epoch [2], val_loss: 0.4748, val_acc: 0.8781\n",
      "Epoch [3], val_loss: 0.4729, val_acc: 0.8785\n",
      "Epoch [4], val_loss: 0.4710, val_acc: 0.8788\n"
     ]
    }
   ],
   "source": [
    "history4 = fit(5, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0], val_loss: 0.4608, val_acc: 0.8810\n",
      "Epoch [1], val_loss: 0.4592, val_acc: 0.8810\n",
      "Epoch [2], val_loss: 0.4577, val_acc: 0.8814\n",
      "Epoch [3], val_loss: 0.4562, val_acc: 0.8813\n",
      "Epoch [4], val_loss: 0.4547, val_acc: 0.8812\n",
      "Epoch [5], val_loss: 0.4533, val_acc: 0.8816\n",
      "Epoch [6], val_loss: 0.4519, val_acc: 0.8817\n",
      "Epoch [7], val_loss: 0.4505, val_acc: 0.8818\n",
      "Epoch [8], val_loss: 0.4491, val_acc: 0.8820\n",
      "Epoch [9], val_loss: 0.4478, val_acc: 0.8820\n"
     ]
    }
   ],
   "source": [
    "history5 = fit(10, 0.001, model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = [result0] + history1 + history2 + history3 + history4 + history5\n",
    "accuracies = [result['val_acc'] for result in history]\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs. No. of epochs');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite clear from the above picture that the model probably won't cross the accuracy threshold of 90% even after training for a very long time. One possible reason for this is that the learning rate might be too high. It's possible that the model's paramaters are \"bouncing\" around the optimal set of parameters that have the lowest loss. You can try reducing the learning rate and training for a few more epochs to see if it helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing with individual images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = MNIST(root='data/', \n",
    "                     train=False,\n",
    "                     transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([1, 28, 28])\n",
      "Label: tensor(7)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Shape:', img.shape)\n",
    "print('Label:', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    xb = img.unsqueeze(0)\n",
    "    yb = model(xb)\n",
    "    _, pred = torch.max(yb, dim=1)\n",
    "    return pred[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(7) , Predicted: 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[0]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: tensor(6) , Predicted: 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img, label = test_dataset[11]\n",
    "plt.imshow(img[0], cmap='gray')\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'mnist-logistic.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .state_dict method returns an OrderedDict containing all the weights and bias matrices mapped to the right attributes of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0112, -0.0329, -0.0057,  ...,  0.0145,  0.0195,  0.0198],\n",
       "                      [-0.0170, -0.0061, -0.0244,  ...,  0.0124, -0.0302, -0.0022],\n",
       "                      [-0.0154,  0.0302, -0.0346,  ...,  0.0218,  0.0228,  0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0268, -0.0179,  0.0162,  ..., -0.0149,  0.0308, -0.0007],\n",
       "                      [-0.0294, -0.0132, -0.0204,  ..., -0.0247, -0.0201,  0.0093],\n",
       "                      [-0.0225, -0.0299,  0.0288,  ..., -0.0093,  0.0012, -0.0187]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0566,  0.1656, -0.0148, -0.0517,  0.0394,  0.1468, -0.0241,  0.1285,\n",
       "                      -0.2420, -0.0318]))])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load the model weights, we can instante a new object of the class MnistModel, and use the .load_state_dict method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear.weight',\n",
       "              tensor([[ 0.0112, -0.0329, -0.0057,  ...,  0.0145,  0.0195,  0.0198],\n",
       "                      [-0.0170, -0.0061, -0.0244,  ...,  0.0124, -0.0302, -0.0022],\n",
       "                      [-0.0154,  0.0302, -0.0346,  ...,  0.0218,  0.0228,  0.0045],\n",
       "                      ...,\n",
       "                      [ 0.0268, -0.0179,  0.0162,  ..., -0.0149,  0.0308, -0.0007],\n",
       "                      [-0.0294, -0.0132, -0.0204,  ..., -0.0247, -0.0201,  0.0093],\n",
       "                      [-0.0225, -0.0299,  0.0288,  ..., -0.0093,  0.0012, -0.0187]])),\n",
       "             ('linear.bias',\n",
       "              tensor([-0.0566,  0.1656, -0.0148, -0.0517,  0.0394,  0.1468, -0.0241,  0.1285,\n",
       "                      -0.2420, -0.0318]))])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = MnistModel()\n",
    "model2.load_state_dict(torch.load('mnist-logistic.pth'))\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': 0.41295480728149414, 'val_acc': 0.891406238079071}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=256)\n",
    "result = evaluate(model2, test_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "style-transfer",
   "language": "python",
   "name": "style-transfer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
